{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# БВТ2003 Токтошев Азирет \n",
        "# Лабораторная работа №1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V1vb3sYe3_v",
        "outputId": "d6a80649-e2bc-4dbc-ba4e-9a4966ca535e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_lab_1.py\n"
          ]
        }
      ],
      "source": [
        "%%file test_lab_1.py\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.functional import conv2d as libConv2d\n",
        "import pytest\n",
        "\n",
        "def Convolution2D(input, kernel, stride=(1,1), padding=(0,0),dilation = 1):\n",
        "    # Получение размеров входного изображения и ядра\n",
        "    input_height, input_width = input.shape\n",
        "    kernel_height, kernel_width = kernel.shape\n",
        "\n",
        "    # Вычисление размеров выходного изображения\n",
        "    output_height = (input_height - dilation*kernel_height + 2 * padding[0]) // stride[0] + 1\n",
        "    output_width = (input_width - dilation*kernel_width + 2 * padding[1]) // stride[1] + 1\n",
        "\n",
        "    # Создание массива для хранения результата свертки\n",
        "    output = np.zeros((output_height, output_width))\n",
        "\n",
        "    # Добавление паддинга к входному изображению\n",
        "    padded_input = np.pad(input, ((padding[0], padding[0]), (padding[1], padding[1])), mode='constant')\n",
        "\n",
        "    # Применение свертки\n",
        "    for i in range(0, input_height - kernel_height + 1, stride[0]):\n",
        "        for j in range(0, input_width - kernel_width + 1, stride[1]):\n",
        "            output[i, j] = np.sum(padded_input[i:i+kernel_height, j:j+kernel_width] * kernel)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def test_1():\n",
        "  image = torch.randn(1,1,5,5)\n",
        "  kernel = torch.randn(1,1,3,3)\n",
        "\n",
        "  myConv2D = torch.from_numpy(Convolution2D(image[0,0].numpy(),kernel[0,0].numpy()))\n",
        "\n",
        "  torchConv2D = libConv2d(image,kernel)\n",
        "\n",
        "  myConv2D = myConv2D.to(torchConv2D.dtype)\n",
        "\n",
        "  assert torch.allclose(myConv2D,torchConv2D)\n",
        "\n",
        "\n",
        "def test_2():\n",
        "  image = torch.randn(1,1,7,7)\n",
        "  kernel = torch.randn(1,1,4,4)\n",
        "\n",
        "  myConv2D = torch.from_numpy(Convolution2D(image[0,0].numpy(),kernel[0,0].numpy()))\n",
        "\n",
        "  torchConv2D = libConv2d(image,kernel)\n",
        "\n",
        "  myConv2D = myConv2D.to(torchConv2D.dtype)\n",
        "\n",
        "  assert torch.allclose(myConv2D,torchConv2D)\n",
        "\n",
        "\n",
        "def test_3():\n",
        "  image = torch.randn(1,1,4,4)\n",
        "  kernel = torch.randn(1,1,2,2)\n",
        "\n",
        "  myConv2D = torch.from_numpy(Convolution2D(image[0,0].numpy(),kernel[0,0].numpy()))\n",
        "\n",
        "  torchConv2D = libConv2d(image,kernel)\n",
        "\n",
        "  myConv2D = myConv2D.to(torchConv2D.dtype)\n",
        "\n",
        "  assert torch.allclose(myConv2D,torchConv2D)\n",
        "\n",
        "\n",
        "def test_4():\n",
        "  image = torch.randn(1,1,8,8)\n",
        "  kernel = torch.randn(1,1,3,3)\n",
        "\n",
        "  myConv2D = torch.from_numpy(Convolution2D(image[0,0].numpy(),kernel[0,0].numpy()))\n",
        "\n",
        "  torchConv2D = libConv2d(image,kernel)\n",
        "\n",
        "  myConv2D = myConv2D.to(torchConv2D.dtype)\n",
        "\n",
        "  assert torch.allclose(myConv2D,torchConv2D)\n",
        "\n",
        "\n",
        "def test_5():\n",
        "  image = torch.randn(1,1,5,5)\n",
        "  kernel = torch.randn(1,1,2,2)\n",
        "\n",
        "  myConv2D = torch.from_numpy(Convolution2D(image[0,0].numpy(),kernel[0,0].numpy()))\n",
        "\n",
        "  torchConv2D = libConv2d(image,kernel)\n",
        "\n",
        "  myConv2D = myConv2D.to(torchConv2D.dtype)\n",
        "\n",
        "  assert torch.allclose(myConv2D,torchConv2D)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLw5_pLFgM9-",
        "outputId": "ab3818e4-50f6-4c76-d9a4-ff2926cbc4e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.3, pluggy-1.3.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "collected 5 items                                                                                  \u001b[0m\n",
            "\n",
            "test_lab_1.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                          [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 3.09s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPQbhonzIQgF",
        "outputId": "f38a8652-ff88-4d07-d0c8-69d194400f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Результат выполнения моей функции Convolution2D:\n",
            "tensor([[ 2.8201,  3.0552, -0.5982, -2.2508],\n",
            "        [-2.7747, -3.5977, -1.5871,  2.2481],\n",
            "        [ 0.3445,  2.4531,  0.8908, -2.2884],\n",
            "        [-1.3608,  1.1278, -0.5575, -1.8636]], dtype=torch.float64)\n",
            "Результат выполнения встроенной функции libConv2D из библиотеки PyTorch:\n",
            "tensor([[[[ 2.8201,  3.0552, -0.5982, -2.2508],\n",
            "          [-2.7747, -3.5977, -1.5871,  2.2481],\n",
            "          [ 0.3445,  2.4531,  0.8908, -2.2884],\n",
            "          [-1.3608,  1.1278, -0.5575, -1.8636]]]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Проверка функции\n",
        "image = torch.randn(1,1,5,5)\n",
        "kernel = torch.randn(1,1,2,2)\n",
        "\n",
        "myConv2D = torch.from_numpy(Convolution2D(image[0,0].numpy(),kernel[0,0].numpy()))\n",
        "print(\"Результат выполнения моей функции Convolution2D:\")\n",
        "print(myConv2D)\n",
        "\n",
        "torchConv2D = libConv2d(image,kernel)\n",
        "print(\"Результат выполнения встроенной функции libConv2D из библиотеки PyTorch:\")\n",
        "print(torchConv2D)\n",
        "\n",
        "myConv2D = myConv2D.to(torchConv2D.dtype)\n",
        "torch.allclose(myConv2D,torchConv2D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGq9rmmOIkf6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
